{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2aad76f1",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-07T13:45:33.324162Z",
     "iopub.status.busy": "2025-11-07T13:45:33.323910Z",
     "iopub.status.idle": "2025-11-07T13:46:48.387094Z",
     "shell.execute_reply": "2025-11-07T13:46:48.386092Z"
    },
    "papermill": {
     "duration": 75.06732,
     "end_time": "2025-11-07T13:46:48.388409",
     "exception": false,
     "start_time": "2025-11-07T13:45:33.321089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\r\n",
      "  Downloading ultralytics-8.3.225-py3-none-any.whl.metadata (37 kB)\r\n",
      "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (1.26.4)\r\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.7.2)\r\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.12.0.88)\r\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.3.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.3)\r\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.5)\r\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\r\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\r\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\r\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (7.1.0)\r\n",
      "Requirement already satisfied: polars in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.25.0)\r\n",
      "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\r\n",
      "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2) (2.4.1)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.59.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\r\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\r\n",
      "INFO: pip is looking at multiple versions of opencv-python to determine which version is compatible with other requirements. This could take a while.\r\n",
      "Collecting opencv-python>=4.6.0 (from ultralytics)\r\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.3)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.19.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.9.0)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2) (2024.2.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\r\n",
      "Downloading ultralytics-8.3.225-py3-none-any.whl (1.1 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\r\n",
      "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, opencv-python, ultralytics\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\r\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\r\n",
      "  Attempting uninstall: opencv-python\r\n",
      "    Found existing installation: opencv-python 4.12.0.88\r\n",
      "    Uninstalling opencv-python-4.12.0.88:\r\n",
      "      Successfully uninstalled opencv-python-4.12.0.88\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 opencv-python-4.11.0.86 ultralytics-8.3.225 ultralytics-thop-2.0.18\r\n",
      "¬°Bibliotecas 'ultralytics' y 'numpy<2' instaladas!\n"
     ]
    }
   ],
   "source": [
    "# --- CELDA 0: INSTALACI√ìN ---\n",
    "# Instala ultralytics Y fija NumPy a una versi√≥n < 2.0 \n",
    "# para evitar conflictos de entorno en Kaggle.\n",
    "!pip install ultralytics \"numpy<2\"\n",
    "\n",
    "print(\"¬°Bibliotecas 'ultralytics' y 'numpy<2' instaladas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "762f5327",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T13:46:48.432796Z",
     "iopub.status.busy": "2025-11-07T13:46:48.432501Z",
     "iopub.status.idle": "2025-11-07T13:47:17.309721Z",
     "shell.execute_reply": "2025-11-07T13:47:17.308936Z"
    },
    "papermill": {
     "duration": 28.900801,
     "end_time": "2025-11-07T13:47:17.310909",
     "exception": false,
     "start_time": "2025-11-07T13:46:48.410108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando la creaci√≥n y re-partici√≥n (80/10/10) del dataset filtrado...\n",
      "\n",
      "--- PASO 1: Filtrando y Unificando Clases ---\n",
      "Procesando split de origen: 'train'...\n",
      "  Se filtraron 2298 etiquetas v√°lidas.\n",
      "  Se copiaron 2298 im√°genes a staging.\n",
      "Procesando split de origen: 'valid'...\n",
      "  Se filtraron 96 etiquetas v√°lidas.\n",
      "  Se copiaron 96 im√°genes a staging.\n",
      "Procesando split de origen: 'test'...\n",
      "  Se filtraron 101 etiquetas v√°lidas.\n",
      "  Se copiaron 101 im√°genes a staging.\n",
      "\n",
      "Filtrado completo. Se unificaron 2495 im√°genes en total.\n",
      "\n",
      "--- PASO 2: Re-partiendo el dataset en 80/10/10 ---\n",
      "Creando split 'train' con 1996 im√°genes...\n",
      "Creando split 'valid' con 249 im√°genes...\n",
      "Creando split 'test' con 250 im√°genes...\n",
      "\n",
      "¬°Proceso de filtrado y re-partici√≥n (80/10/10) completado!\n",
      "Dataset listo en: /kaggle/working/final_dataset_80_10_10\n",
      "  Train: 1996 im√°genes\n",
      "  Valid: 249 im√°genes\n",
      "  Test:  250 im√°genes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import random\n",
    "\n",
    "print(\"Iniciando la creaci√≥n y re-partici√≥n (80/10/10) del dataset filtrado...\")\n",
    "\n",
    "# --- 1. Definir Rutas ---\n",
    "# Ruta base del dataset de SOLO LECTURA\n",
    "INPUT_DIR = '/kaggle/input/graffiti-train-3' \n",
    "\n",
    "# D√≥nde guardaremos el NUEVO dataset final\n",
    "OUTPUT_DIR = '/kaggle/working/final_dataset_80_10_10'\n",
    "\n",
    "# D√≥nde guardaremos temporalmente TODOS los archivos filtrados antes de partirlos\n",
    "STAGING_DIR = os.path.join(OUTPUT_DIR, 'staging')\n",
    "STAGING_IMAGE_DIR = os.path.join(STAGING_DIR, 'images')\n",
    "STAGING_LABEL_DIR = os.path.join(STAGING_DIR, 'labels')\n",
    "\n",
    "# --- 2. Definir Mapeo de Clases ---\n",
    "# Queremos '1' (artistico) -> nueva clase '0'\n",
    "# Queremos '2' (vandalico) -> nueva clase '1'\n",
    "CLASS_MAPPING = {\n",
    "    1: 0,  # 'artistico' se convierte en 0\n",
    "    2: 1   # 'vandalico' se convierte en 1\n",
    "}\n",
    "NEW_CLASS_NAMES = ['artistico', 'vandalico']\n",
    "\n",
    "# --- 3. Limpiar y Crear Directorios ---\n",
    "# Limpiar ejecuciones anteriores\n",
    "if os.path.exists(OUTPUT_DIR):\n",
    "    shutil.rmtree(OUTPUT_DIR)\n",
    "\n",
    "# Crear las carpetas de 'staging' (almacenamiento temporal)\n",
    "os.makedirs(STAGING_IMAGE_DIR, exist_ok=True)\n",
    "os.makedirs(STAGING_LABEL_DIR, exist_ok=True)\n",
    "\n",
    "# --- 4. Procesar y Unificar todos los splits (train, val, test) ---\n",
    "splits_to_process = ['train', 'valid', 'test']\n",
    "total_files_processed = 0\n",
    "\n",
    "print(f\"\\n--- PASO 1: Filtrando y Unificando Clases ---\")\n",
    "for split in splits_to_process:\n",
    "    print(f\"Procesando split de origen: '{split}'...\")\n",
    "    \n",
    "    src_label_dir = os.path.join(INPUT_DIR, split, 'labels')\n",
    "    src_image_dir = os.path.join(INPUT_DIR, split, 'images')\n",
    "    \n",
    "    if not os.path.exists(src_label_dir):\n",
    "        print(f\"  Advertencia: No se encontr√≥ {src_label_dir}. Saltando...\")\n",
    "        continue\n",
    "\n",
    "    images_to_keep = set() # Im√°genes v√°lidas en ESTE split\n",
    "    \n",
    "    for label_file in os.listdir(src_label_dir):\n",
    "        if not label_file.endswith('.txt'):\n",
    "            continue\n",
    "            \n",
    "        src_file_path = os.path.join(src_label_dir, label_file)\n",
    "        dst_file_path = os.path.join(STAGING_LABEL_DIR, label_file) # ¬°Guardar en staging!\n",
    "        \n",
    "        new_label_lines = [] \n",
    "        \n",
    "        try:\n",
    "            with open(src_file_path, 'r') as f_in:\n",
    "                lines = f_in.readlines()\n",
    "            \n",
    "            for line in lines:\n",
    "                if not line.strip():\n",
    "                    continue\n",
    "                \n",
    "                parts = line.split()\n",
    "                original_class_id = int(parts[0])\n",
    "                \n",
    "                # ¬°Aqu√≠ la magia del filtrado!\n",
    "                if original_class_id in CLASS_MAPPING:\n",
    "                    new_class_id = CLASS_MAPPING[original_class_id]\n",
    "                    new_line = f\"{new_class_id} {' '.join(parts[1:])}\\n\"\n",
    "                    new_label_lines.append(new_line)\n",
    "            \n",
    "            if new_label_lines:\n",
    "                with open(dst_file_path, 'w') as f_out:\n",
    "                    f_out.writelines(new_label_lines)\n",
    "                images_to_keep.add(os.path.splitext(label_file)[0])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  Error procesando {label_file}: {e}\")\n",
    "\n",
    "    print(f\"  Se filtraron {len(images_to_keep)} etiquetas v√°lidas.\")\n",
    "\n",
    "    # --- 5. Copiar solo las Im√°genes Relevantes a Staging ---\n",
    "    copied_count = 0\n",
    "    if not os.path.exists(src_image_dir):\n",
    "        print(f\"  Advertencia: No se encontr√≥ {src_image_dir}. Saltando copia...\")\n",
    "        continue\n",
    "        \n",
    "    for img_file in os.listdir(src_image_dir):\n",
    "        base_name = os.path.splitext(img_file)[0]\n",
    "        \n",
    "        if base_name in images_to_keep:\n",
    "            src_img_path = os.path.join(src_image_dir, img_file)\n",
    "            dst_img_path = os.path.join(STAGING_IMAGE_DIR, img_file) # ¬°Guardar en staging!\n",
    "            shutil.copy2(src_img_path, dst_img_path)\n",
    "            copied_count += 1\n",
    "            \n",
    "    print(f\"  Se copiaron {copied_count} im√°genes a staging.\")\n",
    "    total_files_processed += copied_count\n",
    "\n",
    "print(f\"\\nFiltrado completo. Se unificaron {total_files_processed} im√°genes en total.\")\n",
    "\n",
    "# --- 6. Re-partici√≥n 80/10/10 ---\n",
    "print(\"\\n--- PASO 2: Re-partiendo el dataset en 80/10/10 ---\")\n",
    "\n",
    "# Obtener la lista de TODAS las im√°genes filtradas\n",
    "all_image_paths = glob.glob(os.path.join(STAGING_IMAGE_DIR, '*.*'))\n",
    "random.seed(42) # Usar una semilla para que la divisi√≥n sea reproducible\n",
    "random.shuffle(all_image_paths)\n",
    "\n",
    "total_count = len(all_image_paths)\n",
    "if total_count == 0:\n",
    "    print(\"Error: No se encontraron im√°genes filtradas. Deteniendo.\")\n",
    "else:\n",
    "    # Calcular los √≠ndices de divisi√≥n\n",
    "    train_end = int(total_count * 0.8)\n",
    "    valid_end = train_end + int(total_count * 0.1)\n",
    "\n",
    "    # Crear listas de archivos para cada split\n",
    "    splits_files = {\n",
    "        'train': all_image_paths[:train_end],\n",
    "        'valid': all_image_paths[train_end:valid_end],\n",
    "        'test': all_image_paths[valid_end:] # El 10% restante\n",
    "    }\n",
    "\n",
    "    # Mover los archivos desde 'staging' a las carpetas finales\n",
    "    for split_name, image_files in splits_files.items():\n",
    "        print(f\"Creando split '{split_name}' con {len(image_files)} im√°genes...\")\n",
    "        \n",
    "        final_img_dir = os.path.join(OUTPUT_DIR, split_name, 'images')\n",
    "        final_label_dir = os.path.join(OUTPUT_DIR, split_name, 'labels')\n",
    "        os.makedirs(final_img_dir, exist_ok=True)\n",
    "        os.makedirs(final_label_dir, exist_ok=True)\n",
    "        \n",
    "        for img_path in image_files:\n",
    "            base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "            label_file_name = base_name + '.txt'\n",
    "            \n",
    "            src_label_path = os.path.join(STAGING_LABEL_DIR, label_file_name)\n",
    "            dst_label_path = os.path.join(final_label_dir, label_file_name)\n",
    "            \n",
    "            # Mover la imagen\n",
    "            shutil.move(img_path, final_img_dir)\n",
    "            \n",
    "            # Mover la etiqueta\n",
    "            if os.path.exists(src_label_path):\n",
    "                shutil.move(src_label_path, dst_label_path)\n",
    "\n",
    "    # 7. Limpiar la carpeta temporal\n",
    "    shutil.rmtree(STAGING_DIR)\n",
    "\n",
    "    print(\"\\n¬°Proceso de filtrado y re-partici√≥n (80/10/10) completado!\")\n",
    "    print(f\"Dataset listo en: {OUTPUT_DIR}\")\n",
    "    print(f\"  Train: {len(splits_files['train'])} im√°genes\")\n",
    "    print(f\"  Valid: {len(splits_files['valid'])} im√°genes\")\n",
    "    print(f\"  Test:  {len(splits_files['test'])} im√°genes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce5f9900",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T13:47:17.355814Z",
     "iopub.status.busy": "2025-11-07T13:47:17.355308Z",
     "iopub.status.idle": "2025-11-07T13:47:17.379651Z",
     "shell.execute_reply": "2025-11-07T13:47:17.379084Z"
    },
    "papermill": {
     "duration": 0.047297,
     "end_time": "2025-11-07T13:47:17.380688",
     "exception": false,
     "start_time": "2025-11-07T13:47:17.333391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando el archivo YAML para el dataset 80/10/10...\n",
      "Archivo YAML creado exitosamente en: /kaggle/working/data_final_80_10_10.yaml\n",
      "\n",
      "--- Contenido del YAML que se usar√° para entrenar ---\n",
      "train: /kaggle/working/final_dataset_80_10_10/train/images\n",
      "val: /kaggle/working/final_dataset_80_10_10/valid/images\n",
      "test: /kaggle/working/final_dataset_80_10_10/test/images\n",
      "nc: 2\n",
      "names:\n",
      "- artistico\n",
      "- vandalico\n",
      "\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "print(\"Creando el archivo YAML para el dataset 80/10/10...\")\n",
    "\n",
    "# --- ¬°CORREGIDO! ---\n",
    "# Apuntar al directorio que la Celda 1 (80/10/10) realmente cre√≥\n",
    "DATASET_80_10_10_DIR = '/kaggle/working/final_dataset_80_10_10'\n",
    "\n",
    "# D√≥nde guardaremos el nuevo YAML\n",
    "YAML_PATH = '/kaggle/working/data_final_80_10_10.yaml'\n",
    "\n",
    "# Definir la estructura del nuevo YAML\n",
    "yaml_data = {\n",
    "    'train': os.path.join(DATASET_80_10_10_DIR, 'train/images'),\n",
    "    'val': os.path.join(DATASET_80_10_10_DIR, 'valid/images'),\n",
    "    'test': os.path.join(DATASET_80_10_10_DIR, 'test/images'),\n",
    "    \n",
    "    # Clases que definimos en la Celda 1\n",
    "    'nc': 2,\n",
    "    'names': ['artistico', 'vandalico']\n",
    "}\n",
    "\n",
    "# Escribir el archivo YAML\n",
    "with open(YAML_PATH, 'w') as f:\n",
    "    yaml.dump(yaml_data, f, sort_keys=False)\n",
    "\n",
    "print(f\"Archivo YAML creado exitosamente en: {YAML_PATH}\")\n",
    "print(\"\\n--- Contenido del YAML que se usar√° para entrenar ---\")\n",
    "print(yaml.dump(yaml_data, sort_keys=False))\n",
    "print(\"-----------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bbb3184",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T13:47:17.425219Z",
     "iopub.status.busy": "2025-11-07T13:47:17.424693Z",
     "iopub.status.idle": "2025-11-07T13:48:56.345482Z",
     "shell.execute_reply": "2025-11-07T13:48:56.344506Z"
    },
    "papermill": {
     "duration": 98.944791,
     "end_time": "2025-11-07T13:48:56.346867",
     "exception": false,
     "start_time": "2025-11-07T13:47:17.402076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "¬°Hola! Iniciando el script de entrenamiento...\n",
      "Usando archivo YAML: /kaggle/working/data_final_80_10_10.yaml\n",
      "Cargando el modelo YOLOv8s...\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21.5MB 233.0MB/s 0.1s\n",
      "Iniciando el entrenamiento...\n",
      "Ultralytics 8.3.225 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=-1, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/data_final_80_10_10.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=artistico_vandalico_train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=50, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/artistico_vandalico_train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 755.1KB 22.3MB/s 0.0s\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2116822  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \n",
      "Model summary: 129 layers, 11,136,374 parameters, 11,136,358 gradients, 28.6 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.4MB 103.4MB/s 0.1s\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 2993.8¬±1361.2 MB/s, size: 447.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/final_dataset_80_10_10/train/labels... 1996 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1996/1996 1.4Kit/s 1.4s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/final_dataset_80_10_10/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640 at 60.0% CUDA memory utilization.\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla T4) 14.74G total, 0.13G reserved, 0.12G allocated, 14.49G free\n",
      "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
      "    11136374       28.65         0.833         39.78         209.3        (1, 3, 640, 640)                    list\n",
      "    11136374        57.3         1.105         24.52         83.88        (2, 3, 640, 640)                    list\n",
      "    11136374       114.6         1.619         31.03         83.88        (4, 3, 640, 640)                    list\n",
      "    11136374       229.2         2.699         57.25         106.3        (8, 3, 640, 640)                    list\n",
      "    11136374       458.4         4.633         79.79         143.4       (16, 3, 640, 640)                    list\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 33 for CUDA:0 9.23G/14.74G (63%) ‚úÖ\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 2826.6¬±1877.8 MB/s, size: 742.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/final_dataset_80_10_10/train/labels.cache... 1996 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1996/1996 3.4Mit/s 0.0s\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 3163.6¬±2221.9 MB/s, size: 539.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/final_dataset_80_10_10/valid/labels... 249 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 249/249 1.4Kit/s 0.2s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/final_dataset_80_10_10/valid/labels.cache\n",
      "Plotting labels to /kaggle/working/artistico_vandalico_train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.000515625), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m/kaggle/working/artistico_vandalico_train\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        1/1      6.91G      1.293      2.343       1.45         42        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 61/61 1.7it/s 36.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 0.7it/s 6.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        249        366       0.39      0.416       0.34      0.169\n",
      "\n",
      "1 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from /kaggle/working/artistico_vandalico_train/weights/last.pt, 22.5MB\n",
      "Optimizer stripped from /kaggle/working/artistico_vandalico_train/weights/best.pt, 22.5MB\n",
      "\n",
      "Validating /kaggle/working/artistico_vandalico_train/weights/best.pt...\n",
      "Ultralytics 8.3.225 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
      "Model summary (fused): 72 layers, 11,126,358 parameters, 0 gradients, 28.4 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 1.0it/s 4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        249        366       0.39      0.416      0.341      0.169\n",
      "             artistico        127        144      0.307      0.354      0.274      0.111\n",
      "             vandalico        150        222      0.473      0.477      0.408      0.227\n",
      "Speed: 0.3ms preprocess, 5.9ms inference, 0.0ms loss, 4.1ms postprocess per image\n",
      "Results saved to \u001b[1m/kaggle/working/artistico_vandalico_train\u001b[0m\n",
      "\n",
      "¬°Entrenamiento completado!\n",
      "\n",
      "Cargando el MEJOR modelo para la evaluaci√≥n en 'test'...\n",
      "Ejecutando evaluaci√≥n en el set de 'test'...\n",
      "Ultralytics 8.3.225 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
      "Model summary (fused): 72 layers, 11,126,358 parameters, 0 gradients, 28.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 3027.0¬±787.0 MB/s, size: 604.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/final_dataset_80_10_10/test/labels... 250 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 250/250 1.5Kit/s 0.2s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/final_dataset_80_10_10/test/labels.cache\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 2.9it/s 5.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        250        396      0.396      0.412       0.35      0.169\n",
      "             artistico        126        162      0.339      0.444      0.337      0.155\n",
      "             vandalico        149        234      0.453       0.38      0.362      0.183\n",
      "Speed: 2.4ms preprocess, 8.9ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "Results saved to \u001b[1m/kaggle/working/artistico_vandalico_test\u001b[0m\n",
      "\n",
      "¬°Evaluaci√≥n de test completada!\n",
      "\n",
      "--- ¬°Proceso Finalizado! ---\n",
      "Carpeta de Entrenamiento: /kaggle/working//artistico_vandalico_train/\n",
      "Carpeta de Evaluaci√≥n: /kaggle/working//artistico_vandalico_test/\n"
     ]
    }
   ],
   "source": [
    "# ¬°Recuerda poner \"!pip install -q ultralytics\" en la Celda 0!\n",
    "# ¬°No lo pongas aqu√≠!\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "from ultralytics import YOLO\n",
    "\n",
    "print(\"¬°Hola! Iniciando el script de entrenamiento...\")\n",
    "\n",
    "# --- 1. Definici√≥n de Rutas ---\n",
    "\n",
    "# --- ¬°CORREGIDO! ---\n",
    "# Usamos el YAML que creamos en la Celda 2 (el de 80/10/10)\n",
    "YAML_PARA_ENTRENAR = '/kaggle/working/data_final_80_10_10.yaml'\n",
    "\n",
    "# La carpeta de SALIDA (donde se guarda todo)\n",
    "OUTPUT_DIR = '/kaggle/working/'\n",
    "\n",
    "# Nuevos nombres para los experimentos\n",
    "TRAIN_RUN_NAME = 'artistico_vandalico_train'\n",
    "TEST_RUN_NAME = 'artistico_vandalico_test'\n",
    "\n",
    "print(f\"Usando archivo YAML: {YAML_PARA_ENTRENAR}\")\n",
    "\n",
    "# --- 2. Entrenamiento del Modelo ---\n",
    "print(\"Cargando el modelo YOLOv8s...\")\n",
    "model = YOLO('yolov8s.pt') # Cargar el modelo 'small' pre-entrenado\n",
    "\n",
    "print(\"Iniciando el entrenamiento...\")\n",
    "results = model.train(\n",
    "    data=YAML_PARA_ENTRENAR,\n",
    "    imgsz=640,\n",
    "    batch=-1,               # Auto-batch\n",
    "    project=OUTPUT_DIR,\n",
    "    name=TRAIN_RUN_NAME,\n",
    "    exist_ok=True,\n",
    "    \n",
    "    # --- Par√°metros de Entrenamiento ---\n",
    "    epochs=1, # (3 √©pocas es solo para una prueba r√°pida)\n",
    "    #time = 1,  # (Entrenemos por 8 horas, como ten√≠as)\n",
    "    patience=50, # Se detendr√° si no mejora en 50 √©pocas\n",
    "    \n",
    "    # --- ¬°CORRECCI√ìN CR√çTICA! ---\n",
    "    # Debe ser 'False' para evitar el error de Kaggle\n",
    "    amp=True\n",
    ")\n",
    "\n",
    "print(\"\\n¬°Entrenamiento completado!\")\n",
    "\n",
    "# --- 3. Evaluaci√≥n en el Set de TEST ---\n",
    "print(\"\\nCargando el MEJOR modelo para la evaluaci√≥n en 'test'...\")\n",
    "\n",
    "best_model_path = os.path.join(OUTPUT_DIR, TRAIN_RUN_NAME, 'weights/best.pt')\n",
    "\n",
    "if not os.path.exists(best_model_path):\n",
    "    print(f\"ERROR: No se encontr√≥ el modelo en {best_model_path}\")\n",
    "else:\n",
    "    best_model = YOLO(best_model_path)\n",
    "    print(\"Ejecutando evaluaci√≥n en el set de 'test'...\")\n",
    "    \n",
    "    test_results = best_model.val(\n",
    "        data=YAML_PARA_ENTRENAR,\n",
    "        split='test',  # ¬°Perfecto! Usar√° nuestro 10% de 'test'\n",
    "        project=OUTPUT_DIR,\n",
    "        name=TEST_RUN_NAME\n",
    "    )\n",
    "    print(\"\\n¬°Evaluaci√≥n de test completada!\")\n",
    "\n",
    "# --- 4. Resultados Finales ---\n",
    "print(\"\\n--- ¬°Proceso Finalizado! ---\")\n",
    "print(f\"Carpeta de Entrenamiento: {OUTPUT_DIR}/{TRAIN_RUN_NAME}/\")\n",
    "print(f\"Carpeta de Evaluaci√≥n: {OUTPUT_DIR}/{TEST_RUN_NAME}/\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8671800,
     "sourceId": 13642910,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 209.875397,
   "end_time": "2025-11-07T13:48:59.598245",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-07T13:45:29.722848",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
